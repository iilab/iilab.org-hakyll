---
title: Supporting decisions in a complex world
slug: 2015-05-18-decisions-complex-world
date: 2015-05-18
collection: news
format: blog
template: blog.html
tags: decision support, global systems science, influence mapping
images: influence-mapping-map.png
author: kat
projects: r&d
---

As Adam Bly identified in 2012 at Ars Electronica: The Big Picture, complexity is the challenge of our time and what we need is an image that captures it. We think it is critical to develop the tools that will help reduce this complexity to its essentials, and make it easier to understand and more accessible. That way, we can face some of our time's difficult challenges armed with the best information we can get.

<!--more-->

At the edge of the scientific inquiry into how policy decisions are made, iilab's Head of Research and Design, Kat Austen, as part of her consultancy work, is involved in reviewing the European Commission's DG Connect GSS Cluster projects. She recently [reported on a meeting of projects funded in Global Systems Science (GSS) that look at evidence-based policy making](http://ec.europa.eu/digital-agenda/en/news/report-meeting-projects-funded-global-systems-science-gss). It prompted us to think about how understanding and visualising - in the broadest sense of the word - complex systems can help in supporting vital decisions from the individual to the international level.

## Revealing Complex Networks

One of the most important challenges facing our times is climate change, and one of the reasons it's so challenging is because it requires us to have an understanding of our influence within a complex network that is bigger in both space and time than our human experience. Nevertheless, combatting it requires decision-making on every level. GSS's INSITE project looks at the "importance of narrative to society and individuals both in its emergence and its effect" and questions the assumptions behind our models and how much norms influence our ways of thinking about problems. These considerations inform our community based approaches for [Open Droplet](https://iilab.org/projects/open-droplet.html), our open source, open hardware water measurement sensor that will be networked, easy to use and allows people and communities to steward their water use. 

In our research and design, we are paying particular attention to cultural attitudes towards water and how it affects consumption of resources. We'll post here later the results of a 5 city overview undertaken for iilab by UCL Masters students which includes cultural analysis in addition infrastructure and technology analysis. When it comes to stewardship of natural resources, evolving cultural attitudes goes beyond current techniques to prompt behavior change, such as neighbor competition or financial incentives, and is something that we are researching to shape the data interfaces we're developing for Open Droplet - what ways might there be of hinting at our influence in complex networks, without having to show them explicitly?

Sometimes, you do want to see these networks explicitly. We have also recently joined the [Influence Mapping](https://influencemapping.org/) group, which looks at data-driven social network analysis projects to understand influence relationships between people and organisations. It will also map out the network of policy-makers involved in international trade negotiations around the regulation of intellectual property.

## Gathering evidence from open sources

But how do we find out about these networks? Beyond the work that aims to collect evidence about domestic water consumption with Open Droplet, iilab participates in projects where technology is used to improve the collection, analysis and presentation of evidence in ways that involve the public and informs policy making, such as the [Open Integrity Index](/project/open-integrity.html), ECSA (also with DG Connect), the [Open Oil corporate navigator](/project/open-oil.html). 

The text mining and semantic analysis tools developed by the GSS Cluster - for instance the tools used in GLODERS for analysing open source court and police documents - are relevant to our work in facilitating the sourcing of structured evidence by scraping open source documents. When we participated in the Open Oil hackathon in Berlin in January, we explored a number of methods by which to extract this information. For instance, ContentMine has developed new technology which can be used to extract diagrams from PDFs and might be of use to mine information about company organograms. Also Open Oil is now partnering with CrowdCrafting to [crowdsource the analysis of contracts from the oil industry](http://crowdcrafting.org/app/openoil/). 

In the [ECSA project](http://ec.europa.eu/digital-agenda/en/news/no-disconnect-strategy-workshop-european-capability-situational) we also look at how "to augment EU decision-making capabilities with reliable and real-time or almost real-time information concerning human rights violations and/or restrictions of fundamental freedoms in connection with the digital environment." As part of the study we are looking at the feasibility of collecting and analysing information from open sources including internet measurement infrastructure and publicly available reports about potential human rights violation incidents.

## How to trust the evidence?

As we're all aware, not all information online is trustworthy, and as a society we are always navigating who to listen to and what to believe in an era of information overload. The EU Community project aims to address trust and reliability by assigning authority to people and documents. Open Integrity Index, on the other hand, looks into trustworthiness by collecting evidence from the crowd and experts about the practices adopted by tool developers with regards to security and privacy. When submitting evidence it must be accompanied by a link which makes it verifiable by anyone. While there are still challenges around assigning authority to people, particularly when dealing with complex and multi-faceted issues like digital security and privacy,  this transparency and breaking down problems into smaller parts help focus the debate and make the analysis more robust and legible. 

We used this same approach with the [News Verify project](http://newsverify.atchai.com/), in collaboration with Atchai, where we developed a news publishing platform with a verification framework. NewsVerify allows journalists to curate pieces of evidence from social media and the web, and tie them together as news with a verification status and narrative that can be seen by readers and updated as more evidence is added.  Checkdesk from Meedan is further innovating in this domain by developing a liveblogging tool for journalists, with built-in tools to allow citizen journalists and staff journalists alike to make and verify reports. These novel approaches in journalism help open up the way to informed citizen participation in policy making.

## Modelling and Data Analysis

The tools we need to build to address challenges in evidence based decision making should be sophisticated enough to capture the essential complexity of reality, but succeed in being in simple and accessible to their audience and users. Computer science has a lot of room for development to get rid of the non-essential complexity which plagues existing large software systems (cf [Out of the tar pit, B. Moseley & P. Marks 2006](https://github.com/papers-we-love/papers-we-love/blob/master/design/out-of-the-tar-pit.pdf)).  In turn, there are exciting design challenges in making more simple to develop these sophisticated tools in more robust ways, as well as in creating simple, accessible, usable - and in some cases emotive - interfaces with data, and bridging the gap between the digital and corporeal worlds. This can only be the result of a multi-disciplinary effort that is firmly grounded in technological and social innovation.